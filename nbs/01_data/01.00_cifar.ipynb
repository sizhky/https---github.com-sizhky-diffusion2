{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR Dataset\n",
    "\n",
    "> Load the whole/part CIFAR dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | default_exp data.load_cifar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "from nbdev.showdoc import *\n",
    "\n",
    "%reload_ext jupyternotify\n",
    "%reload_ext nb_black\n",
    "%reload_ext autoreload\n",
    "%reload_ext line_profiler\n",
    "%autoreload 2\n",
    "%env CUDA_VISIBLE_DEVICES=\n",
    "\n",
    "import sys\n",
    "\n",
    "__root = \"../../\"\n",
    "sys.path.append(__root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "from torch_snippets import *\n",
    "from simple_ddpm.config.cifar import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | export\n",
    "def denorm(img):\n",
    "    if isinstance(img, list) or img.ndim >= 4:\n",
    "        return torch.cat([denorm(_img)[None] for _img in img])\n",
    "    img = img - img.min()\n",
    "    img = img / img.max()\n",
    "    img = img.permute(1, 2, 0)\n",
    "    return img.float()\n",
    "\n",
    "\n",
    "class CIFAR:\n",
    "    \"\"\"Load CIFAR10 cars dataset\"\"\"\n",
    "\n",
    "    def __init__(self, root, config, **kwargs):\n",
    "        store_attr()\n",
    "        self.transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "            ]\n",
    "        )\n",
    "        self.reverse_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Lambda(denorm),\n",
    "            ]\n",
    "        )\n",
    "        if kwargs.pop(\"load_on_init\", True):\n",
    "            self.data = self.load_trainset()\n",
    "\n",
    "    def __getitem__(self, ix):\n",
    "        return self.data[ix]\n",
    "\n",
    "    def load_trainset(\n",
    "        self,\n",
    "        train: bool = True,  # Is it train or validation subset\n",
    "        download: bool = True,\n",
    "    ):  # Shoud I download if it doesn't exist?\n",
    "        trainset = torchvision.datasets.CIFAR10(\n",
    "            root=self.root, train=train, download=download, transform=self.transform\n",
    "        )\n",
    "        return trainset\n",
    "\n",
    "    def make_dataloader(self, collate_function=None):\n",
    "        dataloader = torch.utils.data.DataLoader(\n",
    "            self.data,\n",
    "            batch_size=self.config.BATCH_SIZE,\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            collate_fn=collate_function,\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    def filter_by_label(\n",
    "        self, trainset: Dataset, label_id: int  # CIFAR Dataset\n",
    "    ):  # Which label id do you want to filter (e.g., 1 is Car)\n",
    "        cache = f\"{self.root}/{label_id}.idxs\"\n",
    "        if exists(cache):\n",
    "            idx = loaddill(cache)\n",
    "        else:\n",
    "            with notify_waiting(f\"Filtering cifar for label-id {label_id}\"):\n",
    "                idx = [\n",
    "                    i for i, (img, label) in enumerate(trainset) if label == label_id\n",
    "                ]\n",
    "            dumpdill(idx, cache)\n",
    "        sub_trainset = torch.utils.data.Subset(trainset, idx)\n",
    "        return sub_trainset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def batch(self, ixs=None, n=9):\n",
    "        if ixs is None:\n",
    "            ixs = [randint(len(self)) for _ in range(n)]\n",
    "        ims = torch.cat([self[ix][0][None] for ix in ixs])\n",
    "        return ims\n",
    "\n",
    "    def show_samples(self, ixs=None, n=9, **kws):\n",
    "        if ixs is not None:\n",
    "            n = len(ixs)\n",
    "        ims = self.batch(ixs=ixs, n=n)\n",
    "        self.show_images(ims, **kws)\n",
    "\n",
    "    def show_images(self, ims, **kws):\n",
    "        ims = [self.reverse_transform(im) for im in ims]\n",
    "        n = len(ims)\n",
    "        if \"nc\" not in kws:\n",
    "            nc = np.sqrt(n)\n",
    "            nc = int(nc) + 1 if int(nc) != nc else int(nc)\n",
    "        else:\n",
    "            nc = kws.pop(\"nc\")\n",
    "        subplots(ims, nc=nc, **kws) if n > 1 else show(ims[0], **kws)\n",
    "        plt.tight_layout()\n",
    "\n",
    "    def generate_noise(self, images):\n",
    "        t = np.random.randint(0, self.config.timesteps, size=len(images))\n",
    "        a = self.config.time_bar[t].reshape(-1, 1, 1, 1)\n",
    "        b = self.config.time_bar[t + 1].reshape(-1, 1, 1, 1)\n",
    "        noise = np.random.normal(size=images.shape)\n",
    "        img_a = (images * (1 - a) + noise * a).float()\n",
    "        img_b = (images * (1 - b) + noise * b).float()\n",
    "        return {\"t\": torch.Tensor(t).float()[..., None], \"x\": img_a, \"y\": img_b}\n",
    "\n",
    "    def generate_noise_collator(self, batch):\n",
    "        ims, _ = zip(*batch)\n",
    "        ims = torch.stack(ims)\n",
    "        return self.generate_noise(ims)\n",
    "\n",
    "\n",
    "class CIFARCars(CIFAR):\n",
    "    def __init__(self, root, config):\n",
    "        super().__init__(root, config, load_on_init=False)\n",
    "        self.data = self.get_cifar_cars()\n",
    "\n",
    "    def get_cifar_cars(self):\n",
    "        return self.filter_by_label(self.load_trainset(self.root), label_id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.BATCH_SIZE = 4\n",
    "data = CIFAR(\"/Users/yeshwanth.y/Downloads/data\", config)\n",
    "ims, _ = next(iter(data.make_dataloader()))\n",
    "data.show_images(ims, nc=len(ims))\n",
    "batch = data.generate_noise(ims)\n",
    "a, b = batch[\"x\"], batch[\"y\"]\n",
    "subplots(\n",
    "    [*denorm(a), *denorm(b)],\n",
    "    nc=len(a),\n",
    "    titles=flatten([[\"input\"] * len(a), [\"output\"] * len(b)]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.BATCH_SIZE = 4\n",
    "data = CIFAR(\"/Users/yeshwanth.y/Downloads/data\", config)\n",
    "dl = data.make_dataloader(collate_function=data.generate_noise_collator)\n",
    "batch = next(iter(dl))\n",
    "a, b = batch[\"x\"], batch[\"y\"]\n",
    "subplots(\n",
    "    [*denorm(a), *denorm(b)],\n",
    "    nc=len(a),\n",
    "    titles=flatten([[\"input\"] * len(a), [\"output\"] * len(b)]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = Config()\n",
    "config.BATCH_SIZE = 8\n",
    "data = CIFARCars(\"/Users/yeshwanth.y/Downloads/data\", config)\n",
    "dl = data.make_dataloader(collate_function=data.generate_noise_collator)\n",
    "batch = next(iter(dl))\n",
    "a, b = batch[\"x\"], batch[\"y\"]\n",
    "subplots(\n",
    "    [*denorm(a), *denorm(b)],\n",
    "    nc=len(a),\n",
    "    titles=flatten([[\"input\"] * len(a), [\"output\"] * len(b)]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# | hide\n",
    "import nbdev\n",
    "\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mdm",
   "language": "python",
   "name": "mdm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
